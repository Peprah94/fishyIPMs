---
#title: "A statistical framework for modelling biodiversity data"
#author: "Kwaku Peprah Adjei"
#date: "`r Sys.Date()`"
bibliography: references.bib
biblio-style: rss
format: 
  pdf:
    keep-tex: false
    number-sections: true
    shift-heading-level-by: 0
    cite-method: natbib
    link-citations: true
    reference-links: true
    reference-location: document
    reference-section-title: "References"
    toc: false
    pdf-engine: "xelatex"
    colorlinks: true
    linkcolor: "black"
    citecolor: "black"
    urlcolor: "black"
output:
  bookdown::pdf_document2:
    number-sections: true
    number-depth: 1
    keep_tex: true
    fig_crop: no
    toc: false
    colorlinks: true
    linkcolor: 'black'
    citecolor: "black"
    #citation_package: biblatex
    cite-method: natbib
    latex_engine: xelatex
#natbiboptions: [giveninits=true,backend=biber,doi=false,isbn=false,url=false]
csl: methods-in-ecology-and-evolution.csl
fontsize:  12pt
#biblio-style: authoryear
documentclass: book
classoption: oneside
#link-citation: true
#link-bibliography: true
#linkcolor: black
header-includes:
  - \usepackage{float}
  - \usepackage{xcolor}
  - \definecolor{mybgcolor}{HTML}{97F0AF}
  - \definecolor{mybgcolor1}{HTML}{BFC9CA}
  - \usepackage{sectsty}
  - \usepackage{paralist}
  - \usepackage{setspace}\spacing{1.5}
  - \usepackage{fancyhdr}
  - \usepackage[newcentury]{quotchap}
  - \usepackage{lastpage}
  - \usepackage{pdfpages}
  - \usepackage{dcolumn}
  - \usepackage{afterpage}
  - \usepackage{bm}
  - \usepackage{algorithm}
  - \usepackage{algpseudocode}
  - \usepackage{rotating}
  - \usepackage{longtable}
  - \usepackage{amsmath,amssymb,amsfonts,amsthm}
  - \usepackage{multirow}
  - \usepackage{setspace}\doublespacing
  - \usepackage{mathtools}
  - \usepackage[sort,round]{natbib}
  - \usepackage[left]{lineno}
  - \usepackage{tabularx}
  - \usepackage{notoccite}
  - \usepackage{booktabs}
  - \setcounter{tocdepth}{1}
  - \usepackage{tocloft}
  #          top=0.8in,
  - \usepackage[a4paper, total={6in, 8in}]{geometry}
editor_options: 
  chunk_output_type: console
---

\newpage

```{=tex}
\setcounter{page}{1} 
\pagenumbering{roman}
```
\newpage

## Preface {.unnumbered}

This thesis is submitted in partial fulfillment of the requirements for the degree of Philosophiae Doctor (PhD) at the Norwegian University of Science and Technology (NTNU) carried out at the Department of Mathematical Science for the period 2019 - 2023.

This PhD work was part of the \textit{Transforming Citizen Science for Biodiversity} project. This project was part of NTNU's digital transformation initiative.

Kwaku Peprah Adjei,

Trondheim, September 2023.

\newpage

## Acknowledgements {.unnumbered}

I cannot believe I am submitting this thesis now. I remember having a meeting with Bob, my main supervisor, three months ago as we discussed the completion of this thesis. This is how far the Lord has brought us, and it is marvelous in my sight. My sincerest gratitude goes to Bob for his patience, encouragement and support throughout my stay with him. My six years with you has shaped my career as an academic, and I am grateful for the knowledge you have passed on to me. At this moment, I contest with Bert (Philip is nowhere close) for the title of your longest serving disciple.

I would also like to thank my co-supervisor Anders for his valuable contributions to this thesis.

I was fortunate to be part of two research groups during my PhD journey, and I really cherish the memories and support I was given. You provided me with a platform to share my ideas and get meaningful feedback to shape my manuscripts. The first group is Bob and Stefie's research group, with Bert, Emma, Emily, Philip, Ron and Janne as members. The second group is the Transforming Citizen Science for Biodiversity group with members Jorge, Philip, Ben, Caitlin, Wouter and Jan.

A significant part of my thesis came from my collaboration with the researchers at the UK Center of Ecology and Hydrology (UKCEH). Your unabated quest to advance in statistical methods to solve ecological research questions has allowed me to learn much from you. I want to acknowledge Nick, Francesca, Rob, Tom, Diana and the entire PhD students there.

Let me take time to appreciate all my office mates with whom I have shared the same space. Thanks to you Jorge, Michail, Karina, Audun and Daniel.

I want to acknowledge Benjamin for helping review the manuscripts in this thesis. I also acknowledge the help I have received from my Church of Pentecost Norway family: the entire ministerial team and members. Thank you for your prayers and encouragement.

I would not have made it this without the help of my supportive family. My heartfelt thanks go to my mother, Florence, and my two brothers, Kwasi and Emmanuel. I want also to thank the Ofori-Mensah family (Eric, Vivian and Kwabena), the Anyan family (Frederick, Christiana, Odomma, Ogyefuor and Otumfuor), the Amoateng family (Yaw, Matilda and Obogya), the Klewiah family (Isaac and Priscilla), the Osei family (Ernest, Linda and children) and any other family that has supported me. Thank you for always being there for me when I needed someone to talk to.

Finally, I would like to thank my wife, Elsie, for being such an excellent partner throughout my PhD journey. You encouraged me in my moments of despair; in my moments of success, you were there to celebrate with me. Every night, you ask a simple question which always means a lot to me: "How is your thesis going?". Here you go. It's done. I love you and Anuonyam.

\newpage

## List of scientific papers {.unnumbered}

This thesis contains the following articles listed here. The R-scripts used for the analysis in each paper can be found on the GitHub repository: \url{https://github.com/Peprah94/finalCodeForThesis} with DOI:\url{https://doi.org/10.5281/zenodo.8359257} . This repository collates a stable version of the R code used for each article. We attach the source code of the R-packages written in this thesis in the repository. For future developments, leading to submission to a scientific journal, we list the repositories to access the new developments as we list the papers included in this thesis.

### Paper One {.unnumbered}

\textbf{Adjei, K. P.}, Sicacha-Parada, J., Steinsland, I., O'Hara, R. B. (2023). A structural model for the process of collecting biodiversity data.

**Link to scripts and dataset:** \url{https://github.com/Peprah94/Data-generating-process}

### Paper Two {.unnumbered}

O'Hara, R. B., \textbf{Adjei, K. P.}, Mostert, P., Sicacha-Parada, J., Skarstein, E. (2023) The point process framework for integrated modelling of biodiversity data.

**Link to scripts and dataset:** \url{https://github.com/emmaSkarste304in/IntegratedLakefish}.

### Paper Three {.unnumbered}

\textbf{Adjei, K. P.}, Cooke, R., Isaac, N., O'Hara, R. B. (2023). Sequential Monte Carlo methods for data assimilation problems in ecology.

**Link to scripts and dataset:** \url{https://github.com/Peprah94/nimMCMCSMCupdates}

### Paper Four {.unnumbered}

\textbf{Adjei, K. P.}, O'Hara, R. B. (2023) Using NIMBLE to implement Markov Chain Monte Carlo with Integrated Nested Laplace approximation.

**Link to scripts and dataset:** \url{https://github.com/Peprah94/INLA_within_nimble}

### Paper Five {.unnumbered}

\textbf{Adjei, K. P.}, O'Hara, R. B., Koch, W., & Finstad, A. (2023). Modelling heterogeneity in the classification process in multi-species distribution models can improve predictive performance. arXiv preprint arXiv:2305.01989.

**Link to scripts and dataset:** \url{https://github.com/Peprah94/misclassification-project}

### Paper Six {.unnumbered}

\textbf{Adjei, K. P.}, Carvell, C., Isaac, N., Mancini, F., O'Hara, R. B. (2023). Integrating data from different taxonomic resolutions to better estimate community alpha diversity.

**Link to scripts and dataset:** \url{https://github.com/Peprah94/Integrated-distribution-models-for-different-taxonomic-levels}

### Paper Seven {.unnumbered}

\textbf{Adjei, K. P.}, Mostert, P., Sicacha-Parada, J., Steinsland, I., O'Hara, R. B. (2023). Modelling species distribution using data from different sources and quality while accounting for uneven sampling effort, imperfect detection and misclassification.

**Link to scripts and dataset:** \url{https://github.com/Peprah94/accountingForObserverErrors}

\newpage

<!-- \section*{\Large Contents} -->

\tableofcontents

\newpage

\newpage

```{=tex}
\setcounter{page}{1} 
\pagenumbering{arabic}
```
\addtocontents{toc}{\protect\setcounter{tocdepth}{1}}


```{=tex}
\chapter{Introduction}
\pagecolor{mybgcolor}\afterpage{\nopagecolor}
\pagestyle{fancy}
\fancyhead{}
\fancyhead[LE,RO]{\thepage}
\fancyhead[LO]{\textit{A statistical framework for modelling biodiversity data}}
\fancyhead[RE]{\textit{Kwaku Peprah Adjei}}
\fancyfoot{}
```
\newpage

## Background

The threat of the loss of biodiversity and the functions of the ecosystem has been a significant concern in recent times. These threats stem from the growing human population and anthropocentric activities that adversely impact the planet [@omann2009climate; @borgelt2022native] and climatic conditions [@bellard2022ranking; @portner2021ipbes]. To effectively make decisions to preserve biodiversity, inferences and predictions about distributions, abundance, species richness and meta-population-derived quantities have become the focus of ecological studies [@kery2015applied; @kery2020applied]. These inferences are needed to make informed management and conservation decisions [@kery2020applied; @bird2014statistical; @kery2015applied]. To achieve this objective, biodiversity data are collected from surveys and other monitoring programs [which includes citizen science where volunteers participate in scientific research @isaac2014statistics; @dennis2017using; @parsons2018value] and by different observers [@kery2020applied; @bird2014statistical]. The importance of biodiversity data in ecological research is highlighted by the influx of biodiversity data hosted on openly available databases that support data standardization and publication [@anderson2020optimizing; @mandeville2021open; @farley2018situating]. These databases include eBird [@sullivan2014ebird], iNaturalist [@matheson2014inaturalist], Artsdatabanken (www.artsdatabanken.no), which are aggregated into the Global Biodiversity Infrastructure Facility [GBIF, @gbif].

However, the observed biodiversity data is subject to observation or measurement process errors [@kery2015applied; @kery2020applied; @adjei2023structural and references therein]. In this thesis, we use bias and errors interchangeably to refer to any mishap between the actual and observed species distribution. While collecting biodiversity data, several factors lead to two main observation errors: false positive and negative errors [@kery2015applied; @kery2020applied; @link2009bayesian]. False negatives occur in almost all datasets of distribution and abundance [@kery2015applied; @chen2013imperfect; @guillera2014ignoring; @kery2005demographic; @kery2003effects; @kery2011bayesian] and are widely addressed in most species distribution models [@link2009bayesian; @kery2011bayesian; @kery2015applied and references therein]. False negative error occurs when a species is present, but not detected. If multiple species are observed by the same individual, then false negative error can also occur when a species is identified as another species [@adjei2023modelling; @adjei2023structural]. False positive error, on the other hand, occurs when an observer over-counts or mis-specifies an individual, indicating that an absent species was reported as present [@kery2015applied; @kery2020applied; @wright2020modelling; @royle2006generalized; @sutherland2013accounting; @chambert2015modeling; @miller2011improving]. These observation errors can lead to biased and more uncertain inferences about species distribution and abundance [@dickinson2010citizen; @gardiner2012lessons; @kosmala2016assessing; @farley2018situating].

Due to the biased inferences the observation errors can cause, much attention has been drawn to ensuring that biodiversity data collected (especially from citizen science monitoring programs) are of good quality [@crall2011assessing; @lewandowski2015influence; @kery2015applied]. The methods that have been implemented to ensure or improve data quality can be put into two broad categories: design-based methods and model-based methods [@clare2021generalized]. The design-based methods involve completely reviewing and implementing proper data collection and processing methods [@clare2021generalized]. The proper data collection methods include proper documentation of sampling design and training of observers, and the processing methods may include ensuring that the observed data can be reviewed, and also validating and filtering the data [@ruiz2016uncertainty; @clare2021generalized; @nichols2011climate; @bird2014statistical]. However, even the best trained observers have been noted in some studies to misclassify observations [@simons2007experimental; @alldredge2008novel], and comparable estimates are obtained from data generated by skilled volunteers and experts [@bird2014statistical; @delaney2008marine; @edgar2009ecological]. In addition, reviewing large datasets can be very burdensome [@ruiz2016uncertainty; @clare2021generalized]. These reasons make the design-based methods difficult to implement and control for observation errors. Therefore, model-based methods are required to accurately account for these observation errors in the biodiversity data, especially since not all heterogeneity in the biodiversity data can be accommodated by improving the study design [@pacifici2016occupancy; @ruiz2016uncertainty].

The model-based methods simultaneously account for these observation errors in species distribution models that are used to infer and predict state variables such as abundance and occupancy. A wide range of models have been developed to account for the observation errors, and @bird2014statistical reviews these statistical models. These modelling approaches, in light of @bird2014statistical, can be summarized as (generalized) linear models, mixed effect models, hierarchical models and machine learning methods. This thesis focuses on the hierarchical models. Hierarchical models are sequences of probability models that are ordered by their conditional probability structure defined by the dependence of the random variables in the model [@kery2020applied; @bird2014statistical]. The hierarchical models that account for observation errors include occupancy models [@royle2006generalized; @ferguson2015occupancy; @clement2022estimating; @mackenzie2002estimating; @spiers2022estimating; @altwegg2019occupancy], N-Mixture models [@kery2020applied; @royle2007hierarchical; @hoekman2021multi] and joint species distribution models [@ovaskainen2011making; @ovaskainen_abrego_2020]. Further discussions on the hierarchical models are presented in section \ref{framework}.

The next sections of this introduction discusses the different biodiversity data types and sources, sources of biases in biodiversity data, a Bayesian framework to model these biases and computational methods to fit these models. The introduction ends with suggestions for further studies on the thesis topic.

## Biodiversity data types \label{dataTypes}

Generally, we can represent species as point patterns, because they are mostly small enough. Therefore, the state variable of interest in most ecological studies can be viewed as derived quantities of a more fundamental quantity: point patterns [@kery2015applied]. These point patterns are realisations of a point process (which we assume are stochastic), and the models developed to describe the point process are referred to as point process models [PPM hereafter @illian2008statistical; @wiegand2013handbook; @kery2015applied]. PPMs treat the number of observations as well as their locations as random quantities driven by an underlying continuous intensity field. This intensity is the expected number of points per unit area in some study area of interest, and it describes the density of the points in the given area [@kery2015applied; @dorazio2014accounting].

A statistical definition of PPMs is provided here. Let $D \subset R^2$ be a bounded region (study domain) and $\textbf{s} \in D \subset R^2$ be a location in the study domain. Then the expected number of individuals in the study region $E(N(D))$ is defined as: \begin{equation}\label{trueIntensity}
E(N(D)) = \lambda(D) = \int_D \lambda(s)ds,
\end{equation} where $\lambda(D)$ is the intensity function. Let $A$ denote a spatial point pattern for a single species throughout this discussion.

Given the spatial point pattern for a single species, abundance and occurrence can be seen as areal summaries of the point patterns [@kery2015applied]. Using this definition, we discuss three data types (defined in terms of the units they are measured in) primarily generated from biodiversity monitoring programs. These are the presence-only, presence-absence and count data.

```{r, echo = FALSE, message = FALSE, warning = FALSE}
#| label: fig-simIntensity
#| fig-cap: Relationship among the three biodiversity types considered in this thesis - presence only data which is just a collection of point patterns (top left), presence/absence or occurrence data (bottom left) which is a binary summary of the occupied cells (colured in black) and unoccupied cells (colored in white) and the count or abundance data (top right) which provides the counts in each grid cell (coloured in blue). Shown in the bottom right is the distribution of cell based abundance along with its mean colored in blue (which is the estimate of the Poisson mean $\lambda$). This plot was generated using the function $sim.fn$ in the R package \textbf{AHMbook}.
#| fig-height: 10
#| fig-width: 14
library(AHMbook)
set.seed(1994)
tmp <- sim.fn(quad.size = 10, cell.size =2, intensity = 0.2)
```

### Presence-only data

Presence-only data consist of taxonomic identification and location of records, usually with no further information on the occurrence, abundance and sampling design. These reported presences are often treated as point processes, and can be seen as a trivial extension of the basic point pattern definition, as illustrated in Figure \ref{fig-simIntensity}.

Presence-only occurrence records are the most reported data type to biodiversity databases such as GBIF [@mandeville2021open; @anderson2020optimizing; @konig2019biodiversity; @gadelha2021survey]. The predominance of presence-only records in the biodiversity databases can be attributed to two main drivers. The first factor is the popularity of citizen science platforms (where opportunistic collected data are submitted) and the aggregation of historical records and museum specimen [@mandeville2021open; @theobald2015global; @ball2019research]. The second factor is the characteristics of the presence-only records: they are relatively simple to collect and can be easily standardized within the existing practices of data sharing [@mandeville2021open]. Therefore presence-only records presents an enormous opportunity to model species distribution on larger scales. However, these records lack information on species absence, thereby presenting a limitation in modelling species occurrences.

In this thesis, we accessed presence-only records from iNaturalist and eBird through GBIF and combined them with other the other types of data to fit species distribution models.

### Count data

During biodiversity data collection, species counts may be reported. These counts are aggregate sums of the underlying true point patterns in a discretized domain, as presented in Figure \ref{fig-simIntensity}. The counts are used to model species abundance.

Examples of biodiversity programs that generate count data include the Big Butterfly Count (\url{https://bigbutterflycount.butterfly-conservation.org/}) from the U.K. Butterfly Monitoring scheme (UKBMS) where 15-minute counts of $18$ butterfly species are provided [@dennis2017using]; Flower-Insect Timed (FIT) counts from the UK Pollinator monitoring scheme [@o2019monitoring; @breeze2021pollinator] where all insects landing on a target flower in a $50 \times 50$cm patch is counted, bat counts from NEON acoustic monitoring program [@hoekman2017design], Swiss Crested Tit counts from the Swiss Breeding survey [@schmid2004monitoring], etc.

The count data we used in paper six of this thesis was from the Flower-Insect Time counts and paper three was from the Swiss Breeding survey.

### Presence-absence data

Some generated biodiversity data, especially those generated from structured surveys (to be described in section \ref{structured surveys}), provide information on the presence and absence of species in a location. Given that the domain $D$ is divided into discrete space (for example, as grid cells or areal locations), then the presence-absence data is an aggregate of the point patterns in a given grid cell indicating whether at least one species was present in the given discretized space, as illustrated in Figure \ref{fig-simIntensity}. The species absence and presence information (which is binary) from this data type is used to estimate species occupancy. A related data type that also has a binary outcome, but subject to imperfect detection, is the detection/non-detection data.

Examples of biodiversity monitoring programs that generate occurrence data include the Norwegian common bird monitoring program (ToV-E) coordinated by Norwegian Institute of Nature Research (NINA; \url{https://www.nina.no/}) and the Norwegian Ornithological Association, pan trap data from the UK Pollinator monitoring scheme [@o2019monitoring; @breeze2021pollinator], complete checklists from eBird monitoring program [@johnston2019best; @johnston2021analytical]. We use these occurrence data in papers three, six and seven.

## Biodiversity data sources \label{dataSources}

The biodiversity data described above are generated from various monitoring schemes or surveys. We discuss three main groupings of these monitoring surveys: structured, semi-structured and unstructured. This classification is made to highlight the data quality issues, and its corresponding use in scientific research. A summary of the data sources are presented in Figure \ref{fig-dataQualitySource}.

Data quality, as discussed here, is "the mixture of data accuracy and planned analyses, ... the threshold for accuracy that allows one to achieve a specific analytical objective" [@clare2019making]. That is, we describe the quality of data in terms of how it meets a research objective, the expertise of the data collectors, the survey design used to collect the data and the availability of meta-data to model biases in the data. If a data is collected by experts or scientist to answer a particular research question - say the trend of gull abundance in Norway - and a proper and complete sampling design is implemented, then this data is regarded as having good quality. The goal of ensuring data quality is that the data generated are less susceptible to observation errors, leading to better inferences on the ecological state [@clare2019making].

### Structured surveys \label{structured surveys}

Structured or professional surveys provide long-term, standardized data that are used to produce timely and robust estimates of trends and status [@isaac2014statistics; @gantchoff2022effectiveness]. These surveys require proper sampling design and protocols, complete data collection procedures and are usually collected by experts in the field [@kelling2019using]. These structured surveys usually generate occupancy and count data, typically providing much information to estimate species distributions and abundance. Due to the proper planning of these surveys, they are considered to be of high quality [@kelling2019using]. Although data collected from these surveys are of good quality, they are usually difficult to obtain, due to relatively high cost and logistics involved in collecting them, especially for wide-ranging and cryptic species [@gantchoff2022effectiveness; @isaac2014statistics; @parsons2018value]. An example of the structured survey is the United Kingdom Butterfly Monitoring scheme (UKBMS), Swiss Breeding bird survey and the Norwegian common bird monitoring program described in section \ref{dataTypes}.

### Unstructured surveys

The unstructured surveys, also referred to as opportunistic surveys, engage a wide range of observers - with differing experience and observer effort - to generate substantial information and promote a better understanding and awareness of biodiversity [@santos2021understanding; @isaac2014statistics; @dennis2017using; @bird2014statistical]. Additionally, these surveys do not have prescribed protocols, making it difficult to control a \textit{priori} observer quality and ensure data standardization [@kery2020applied; @zbinden2014resampling; @warton2013model]. These surveys, compared to the structured surveys, are less expensive to implement and do have wider spatial coverage [@isaac2014statistics; @gantchoff2022effectiveness].

Due to the openness of the survey to variation in sampling protocols and effort, data generated from the unstructured surveys are considered to be of lower quality than those from structured surveys [@dickinson2010citizen; @bird2014statistical; @kelling2019using]. This has led to skepticism in the use of data from opportunistic surveys in scientific research [@chapman2020developing; @gaiji2013content]. However, data from these surveys are becoming extremely valuable in scientific research [@bonney2014next; @howe2008crowdsourcing; @santos2021understanding; @pocock2018vision], partly due to the advancement in modelling them together with those from structured surveys.

Examples of biodiversity projects that employ opportunistic surveys are those implemented by iNaturalist (\url{www.inaturalist.org}), Biodiversity4all (\url{www.biodiversity4all.org}) and Christmas Bird Count [@butcher1990audubon].

### Semi-structured surveys

Biodiversity surveys are on the continuum, with the unstructured and structured surveys at the opposite ends, as displayed in Figure \ref{fig-dataQualitySource}. Semi-structured surveys use a flexible and straight-forward data collection procedure and minimal survey design which a broad scale of participants can use [@kelling2019using]. Furthermore, they do not limit where and when observers can collect data, but rather requires them to gather meta-information about the sampling and data collection process such as time spent in collecting data, time of the day, etc [@kelling2019using]. This extra information is used to model the variation in species abundance and distribution over space and time [@kelling2019using]. Examples of biodiversity monitoring programs that employ semi-structured surveys include eBird [@sullivan2014ebird] and North American Breeding Bird Survey [@sauer2005north; @bystrak1981north].

```{r, echo=FALSE, fig.align='center', out.width='100%'}
#| fig-cap: Characteristics of unstructured, semistructured and structured citizen science projects described in this introduction. Source - @kelling2019using.
#| label: fig-dataQualitySource
#| fig-width: 10
#| fig-height: 16

knitr::include_graphics("structureUnstructured.png")
```

## Sources of biases in biodiversity data

As discussed in the introduction, biodiversity data contain observation errors. These observation errors are either false positives or false negatives in the data. This thesis will discuss the following sources of observation errors in biodiversity data: imperfect detection, uneven sampling effort, misclassification, reporting bias and taxonomic bias.

### Imperfect detection

It is nearly impossible to sample all individuals present in a community [@richter2021hidden]. This can be because of limited time and resources, visibility conditions, and the observers' attention to particular species. Also, different species have different detection probabilities [@richter2021hidden; @chao2017deciphering; @guillera2019inferring; @yoccoz2001monitoring], which may be due to the species' biology and behavior [ecological traits and abundance, for example singing birds can have high detection probability @morelli2022detection], individual species heterogeneity (such as age and sex), the survey design (for instance, distance sampling designs may have low detection than transect counts) and skills of the observer. Consequently, during field surveys, conspicuous species may escape the detection of observers.

Imperfect detection is usually estimated and adjusted for in species distribution models, usually with biodiversity data collected from repeated visits [@dorazio2014accounting; @koshkina2017integrated; @erickson2021accounting]. Failure to do so leads to overestimating species distribution and abundance [@royle2006generalized; @welsh2013fitting].

### Uneven sampling effort

Biodiversity data, especially those generated from unstructured surveys, are influenced by uneven sampling effort. This inconsistent effort can be due to the sampling process's temporal, spatial and environmental biases [@pardo2013novel; @ballesteros2013mapping; @monsarrat2019accessibility]. Temporal variations in sampling effort arise from differences in time taken to sample various locations [@pardo2013novel], the time of the day or season data is collected. Intuitively, the more time an observer spends to collect data, the more likely it is that they cover a large spatial scale; and observers are more likely to collect data in summer (when the weather conditions are favorable to go on walks) than winter (when the weather conditions makes staying indoors the preferred choice). The spatial and environmental variations, on the other hand, occur when some locations are sampled more than others and this leads to an accumulation of biodiversity records at some locations [@pardo2013novel; @ballesteros2013mapping; @monsarrat2019accessibility]. The unbalanced spatial sampling can be due to economic and political factors [with more data collected by developed countries than developing countries due to the availability of funds for biodiversity data collection @amano2013four; @meyer2015global], easy accessibility to sampled areas [especially areas with urban infrastructure such as roads and highways and rivers @pautasso2007botanist; @yang2014environmental] and areas considered by observers to be attractive [such as mountains, hotspot regions and protected regions where high values of species diversity can be obtained @ballesteros2013mapping; @yang2014environmental].

Uneven sampling effort can be ameliorated by considering a few approaches. Sampling coverage and reliability can be provided through maps of ignorance [@rocchini2011accounting; @ruete2015displaying; @hortal2007limitations] and maps that collect effort [@schulman2007analysing]. In addition, spatial models of the distribution of effort based on occurrence data and where observers are likely to collect data can be explored [@stolar2015accounting]. The uneven sampling effort are accounted for in SDMs by spatial filtering of occurrence data [@boria2014spatial; @fourcade2014mapping; @varela2014environmental], weighting sample points according to sampling effort distribution [@stolar2015accounting], generating pseudo-absences or background data using all occurrences within a target group as absence under the assumption that all the occurrences share the same geographical bias [@phillips2009sample; @hertzog2014field; @ranc2017performance] and jointly estimating and accounting for spatial bias by incorporating presence-only data and presence-absence data [@fithian2015bias; @dorazio2014accounting; @simmonds2020more].

### Misclassification

Observations from imperfect classifiers leads to misclassifications in biodiversity data [@spiers2022estimating; @wright2020modelling]. The imperfect classifiers can be image recognition machine learning algorithms [for example, convolution neural network applied to camera trap data @tabak2019machine], taxonomically trained technicians [for example, invertebrate trapping of NEON @hoekman2017design], automated methods [such as bat acoustic recording software @wright2020modelling] and citizen scientists. The species classifications from these classifiers are not always resolved to the species level, and they can include other unknown morphospecies designations and taxonomic identifications coarser than species [@spiers2022estimating]. Morphospecies are species that are separated from the other species based on their recognized clear morphological features [@morphospecies]. As a result, methods employed to deal with misclassification need to take into account all possible taxonomic classifications that can be made.

Methods developed to deal with misclassification assign species identities to individuals through a verification process [for example, community verification in iNaturalist @matheson2014inaturalist]. Then species distribution models can be developed to simultaneously model the classification and ecological process in one model [@chambert2015modeling; @wright2020modelling; @clement2022estimating].

### Reporting bias

Observers are likely to report observations of particular interest to them [@buzinkai2023crowdsourcing; @roberts2022many]. Reports of biodiversity data can be influenced by the quality of images an observer was able to take, how easy observers can upload records to databases, among many others. Reporting biases typically lead to false negatives, and are usually treated as confounded with imperfect detection. Moreover, by restricting observations to one or few taxonomic groups, observers have high motivation to report any records they have than be selective on what they can report [@buzinkai2023crowdsourcing; @michonneau2015using].

### Taxonomic bias

Reports of biodiversity data are skewed towards some taxonomic groups. To be fair, all species are not equally abundant, and so it is reasonable to expect the common species to be more abundant in the observed data too [@koch2022improving]. Studies have shown that plants and vertebrates are over-represented in various fields [@feeley2017most; @bonnet2002taxonomic; @troudet2017taxonomic]. One study by @koch2022maximizing showed that more colorful insects like butterflies, birds and dragonflies are over-represented in the Norwegian citizen science data with images, and the less conspicuous insects like flies and beetles are under-reported, as displayed in Figure \ref{fig-taxonomicBias}. A number of factors, including easy access to funds to collect data on these taxon [@leather2009taxonomic], differences in knowledge on the different taxon, and the consideration that these taxon are of more ecological importance than the others [@troudet2017taxonomic], can cause this taxonomic bias in the generated data.

```{r, echo=FALSE, fig.align='center'}
#| fig-cap: Results from @koch2022maximizing showing the over-representation (colored in green) and under-representation (colored in red) of species in citizen science image data. The expected benefit for a recorgnition model when adding one more image to what is currently available is represented by the areas of the circles.
#| label: fig-taxonomicBias
#| fig-height: 10
#| fig-width: 14
#| fig-pos: 'ht'
knitr::include_graphics("taxonomicBias.jpeg")
```

For taxonomic bias to occur, a taxon has to be present in the location sampled by the observer, then given that the taxon is detected, the observer reports it. Somehow, the taxonomic bias can be confounded into the reporting bias, uneven sampling effort or imperfect detection, if there are no extra information on the taxonomic differences.

The taxonomic bias can be addressed by using remotely operated vehicles, acoustic monitoring devices, etc to generate a representative subset of each taxa [@koch2022maximizing]. The additional representative samples can improve the inferences and predictions from species distribution models, as discussed by @koch2022maximizing and illustrated with Figure \ref{fig-taxonomicBias}.

## Bayesian Framework to model biodiversity biases \label{framework}

We have mentioned that biodiversity data are subject to observation errors. The methods to deal with them are either design-based or model-based. The design-based methods are difficult to implement and control for the observation errors. Therefore, model-based methods have gained popularity in ecological applications. Here, we discuss a Bayesian framework to model the observation errors in biodiversity data. We do this by focusing on the contributions made by the papers included in this thesis to modelling biases in biodiversity data.

### Hierarchical structure for collecting biodiversity data

In paper one, a structural model for the process of collecting biodiversity data is presented. The biodiversity data are assumed to be a realization of a thinned point process, where the actual species distribution and abundance point patterns ($A$) are thinned by the sources of biases.

Mathematically defined, a point pattern $A_t$ is thinned when a specified rule determines which points in the original point pattern $A$ are deleted. There are three thinning rules that have been described by @illian2008statistical:

-   p-thinning: This rule assumes that each point in the pattern $A$ are deleted with probability $1-p$, and this rule is independent of the location of the points $\textbf{s} \in D$.

-   $p(\textbf{s})$-thinning : This rule defines a deterministic function $p(\textbf{s})$, which is dependent on location $\textbf{s} \in D$. This function $p(\textbf{s})$ determines whether a point will be deleted or not. The rest of the thesis uses this thinning rule.

-   $P(\textbf{s})$- thinning : This rule specifies different deletion rules for different regions in the study domain $D \subset R^2$. The deletion of points in one sub-region is independent of the others and the probability of deleting a point is now assumed to be a realisation from a random process $P(\textbf{s})$, which is independent of $A$.

The thinned point process $A_t$ will have its intensity, $\lambda_t(\textbf{s})$, defined as: \begin{equation}\label{observedIntensity}
\lambda_t(\textbf{s}) = p(\textbf{s}) \lambda(\textbf{s}),
\end{equation} where $\lambda(\textbf{s})$ is the intensity of the point process of $A$ defined in equation \eqref{trueIntensity}.

To properly define the thinning rule $p(\textbf{s})$, paper one explored how the various sources of biases thin the actual point pattern $A$. The true point pattern $A$ is first thinned by a function, say $\zeta(\textbf{s})$, which defines the probability that a given location in the study region $D$ is sampled. That is, the first source of bias accounted for is the uneven sampling effort. Given that we condition on the taxonomic bias, then we define another function, $\psi(\textbf{s})$, which describes the probability that the species are detected. This function further thins the point pattern $A$. The final thinning function explored in paper one is the probability of classifying a species. Given that we condition on the reporting bias, then the true point pattern $A$ is further thinned by the classification probabilities $\Omega(\textbf{s})$. This hierarchical structure is presented with the nodes linked with thick solid lines in Figure \ref{fig-flowchart}. The resulting observed point pattern $A_t$ defined in equation \eqref{observedIntensity} has intensity: \begin{equation}\label{observedIntensity1}
\lambda_t(\textbf{s}) = \lambda(\textbf{s}) \times \zeta(\textbf{s}) \times \psi(\textbf{s}) \times \Omega(\textbf{s}),
\end{equation} where $\lambda(\textbf{s})$ is the intensity of the point process of $A$ defined in equation \eqref{trueIntensity}.

```{r, echo=FALSE, fig.align='center'}
#| fig-cap: Flowchart showing the hierarchical relationship of the various sources of biases described in this thesis. The relationship we explored in paper one is indicated with thick solid arrows and the biases we described are colored in purple; the relationship of the sources of biases is indicated with the solid thin lines and the biases that can be confounded in others are indicated with thin dashed lines.
#| label: fig-flowchart
#| fig-height: 10
#| fig-width: 18
knitr::include_graphics("flowchartThesis.png")
```

The structural process presented in paper one is not a cast in stone one. The hierarchical nature of the biases are more complicated than presented in the paper. Figure \ref{fig-flowchart} presents a general overview of the inter-relatedness of the sources of biases in the Bayesian framework. All the sources of biases can be described in a general hierarchical model by first accounting for uneven sampling effort, then taxonomic bias, imperfect detection, reporting bias and then misclassification (shown by the solid thin lines in Figure \ref{fig-flowchart}). However, some of the sources of biases can be confounded in others depending on the sampling design and data collection and processing methods. For example, monitoring programs that collect biodiversity data on one taxon, for example data collected on birds in eBird [@sullivan2014ebird] and North American breeding bird survey [@bystrak1981north; @sauer2005north], can ignore the taxonomic bias and treat the reporting bias as confounded in the sampling bias or imperfect detection, since observers are required to report information on a checklist.

### Bayesian Modelling Framework

To account for the biases in biodiversity data, there is the need to develop a model that simultaneously describes the state and observation processes. Specifically, we discuss a hierarchical model that provides a sub-model for the true state of interest and sub-model(s) for the sources of biases. The sub-model for the state variable is known as the process model and the sub-models to model the biodiversity data biases are known as observation models. These hierarchical models are flexible and allow us to include in a single model, multiple datasets, multiple sources of variability such as spatial, temporal, spatio-temporal variability and rigorously propagate the combined uncertainty in every estimand in the model [@kery2015applied]. The integration of data from different sources and quality is referred to as data integration [@isaac2020data].

We have mentioned in section \ref{dataTypes} that the ecological state of interest (abundance and occupancy) are derived quantities of point patterns [@kery2015applied]. In this thesis, we are interested in modelling the state process by relying on this relationship. Hence, we defined a point process framework for integrated modelling of biodiversity data in paper two, by assuming a PPM for the state process [@dorazio2014accounting; @Aarts2012]. The distribution of points in the study region $D$ can be modeled either as an inhomogeneous point process with intensity: \begin{equation}
\ln(\lambda(\textbf{s})) = \eta(\textbf{s}) = \sum_{i = 1}^{P} \beta_i X_i(\textbf{s})),
\end{equation} or as a log-Gaussian Cox process with intensity [@moller2003statistical]: \begin{equation}
\ln(\lambda(\textbf{s})) = \eta(\textbf{s}) = \sum_{i = 1}^{P} \beta_i X_i(\textbf{s}) + \omega(\textbf{s}),
\end{equation} where $X_i(\textbf{s})$ is the $i^{th}$ spatial covariate and $\omega(\textbf{s})$ is a random field that models the residual spatial effects. In practice, $\omega(\textbf{s})$ is assumed to be a zero-mean Gaussian Random field with MatÃ¨rn covariance function defined as: \begin{equation}\label{matern}
\frac{\sigma^2}{\Gamma(\nu) 2^{\nu - 1}} (\kappa ||s_i - s_j||)^{\nu} K_{\nu}(\kappa ||s_i - s_j||)
\end{equation} where $||s_i - s_j||$ is the euclidean distance between two locations $s_i, s_j \in D$. The parameter $\sigma^2$ is the marginal variance, and $K_{\nu}$ denotes the Bessel function of the second kind and of order $\nu > 0$. The parameter $\nu$ determines the degree of smoothness of the process and $\kappa$ is the scaling parameter.

Given the process model assumed, observation models can be developed to link the state and observation process as outlined in paper two. These hierarchical models usually contain many parameters which may lead to identifiability issues. These identifiability issues arise because different combinations of parameters can produce the same likelihood or posterior probability [@raue2013joining; @rannala2002identifiability; @wieland2021structural] or the available data cannot inform the hierarchical models about the effects of interest [@ogle2020ensuring; @raue2013joining]. Fitting the hierarchical models with multiple data types can help inform the estimation of all the model parameters. Specifically, data from different taxonomic levels can be integrated together (as described in paper six) and a multiple multinomial logistic regression can be used to account for heterogeneity in the misclassification by obtaining data on verification process (as described in paper five). In addition, we defined logistic regression models with covariate effects to model imperfect detection and uneven sampling effort and a multinomial model for classification probability by integrating presence/absence and presence-only data in paper seven.

We present three basic hierarchical models used in this thesis to fit count and occurrence data below:

::: callout-note
## Occupancy Model fitted to presence-absence data

Let $\psi$ be the occupancy probability, $p$ be the detection probability, $z$ be the latent occupancy state and $y$ be the occurence data:

\textbf{State process:} $z|\psi \sim \text{Bernoulli} (\psi)$

\par

\textbf{Observation process:} $y|z, \psi \sim \text{Bernoulli} (z * p)$
:::

::: callout-note
## N-Mixture model fitted to count data

Let $\lambda$ be the intensity, $p$ be the detection probability, $N$ be the latent abundance and $y$ be the count data:

\textbf{State process:} $N|\lambda \sim \text{Poisson} (\lambda)$

\par

\textbf{Observation process:} $y|N, p \sim \text{Binomial} (N, p)$
:::

::: callout-note
## State-space models to model trends in abundance

Let $\lambda_0$ be the initial intensity, $t$ be the time index, $p$ be the detection probability, $N$ be the latent abundance and $y$ be the count data:

\textbf{Initial state distribution:} $N_0|\lambda_0 \sim \text{Poisson} (\lambda_0)$

\par

\textbf{State process:} $N_t|N_{t-1},\lambda_t \sim \text{Poisson} (N_{t-1}\lambda_t)$

\par

\textbf{Observation process:} $y|N_{t}, p \sim \text{Binomial} (N_{t}, p)$
:::

In order to make inference about the actual distribution and abundance whilst accounting for the sources of biases, the Bayesian modelling framework will be employed. We assume that the model parameters are random variables and their prior distribution needs to be specified in order to obtain their posterior distribution. This posterior distribution will be used to make the inferences and predictions about the species distributions.

Mathematically, let us assume that $\theta$ is a collection of the model parameters we are interested in making inference on, $\pi(\theta)$ be the prior distribution expressing our prior knowledge about $\theta$ and $y$ be the data. Then the aim of Bayesian inference is to update our prior knowledge based on the Bayes' theorem: \begin{equation}
\pi(\theta| \textbf{y}) = \frac{\pi(\theta) \pi(\textbf{y}|
\theta)}{\pi(\textbf{y})} \propto \pi(\theta) \pi(\textbf{y}|\theta),
\end{equation} where $\pi(\textbf{y}|\theta)$ is the likelihood function and $\pi(\theta | \textbf{y})$ is the posterior distribution.

The assigned priors can be chosen through prior elicitation [for example, priors based on expert opinion @mikkola2021prior; @carlin2008bayesian], selecting distributions that are conjugate to the likelihood distribution [@carlin2008bayesian; @kery2015applied], using non-informative priors [@carlin2008bayesian] and penalised complexity (PC) priors [@fuglstad2019constructing; @simpson2017penalising].

## Computational methods: Existing and advances \label{computationalMethods}

In the previous section, it has been discussed that Bayesian framework will be used to implement the hierarchical models in this thesis. After the hierarchical model has been defined and prior distribution specified for the parameters $\theta$, the posterior distribution can be computed. In this thesis, we explore the following computational methods:

### Markov Chain Monte Carlo (MCMC) methods \label{mcmc}

MCMC methods aim to draw random samples from the posterior distribution of the parameter $\theta$. Although the posterior distribution may not be known analytically, large samples can be simulated from the posterior and summaries of the simulated values calculated to characterize the posterior [@kery2015applied]. For example, if we want to obtain the posterior mean of $\theta$, and we are able to simulate $M$ samples from the posterior distribution, then the Monte Carlo estimate of $\theta$ can be computed as: \begin{equation}
E(\theta| \textbf{y}) = \frac{1}{M}\sum_{m=1}^{M} \theta^{(m)}.
\end{equation}

Two sampling algorithms are usually used for MCMC: Metropolis-Hastings and Gibbs sampling algorithms. Metropolis-Hasting (MH) algorithm, proposes samples from a distribution $\pi(\theta^{\star}|\theta^{t-1})$, which is accepted with probability: \begin{equation}\label{MCMC-MH}
\alpha = min \bigg(1, \frac{\pi(\theta^{\star}) \pi(\theta^{t-1}|\theta^{\star})}{\pi(\theta^{t-1}) \pi(\theta^{\star}|\theta^{t-1})}  \bigg),
\end{equation} with $\pi(\theta^{\star})$ and $\pi(\theta^{t-1})$ being the distribution of $\theta^{\star}$ and $\theta^{t-1}$ respectively. The Gibbs algorithm, on the other hand, draws samples from the conditional posterior of each parameter by holding the other parameters constant.

MCMC methods are popular due to the availability of numerous software to implement them. They include JAGS [@depaoli2016just], BUGS [@lunn2009bugs], Stan [@carpenter2017stan], GRETA [@golding2019greta], NIMBLE [@de2017programming]. In this thesis, the MCMC methods used are run with NIMBLE through its R-package \textbf{nimble} [@nimblepackage].

### Sequential Monte Carlo (SMC) methods

SMC methods are usually used when state-space models are fitted to time-series data generated from biodiversity monitoring programs. The SMC methods draw samples of some latent state, $\textbf{x}$, from a distribution and correct these samples with calculated weights to obtain the posterior distribution of $\textbf{x}$.

More technically, SMC methods employ the sequential importance sampling technique to estimate the filtering distributions [@doucet2001introduction; @michaud2021sequential]. At each time step $t$, a latent state $x_t$ is proposed from a distribution or importance function that depends on the latent state at time step $t-1$, $\pi(x_t|x_{t-1}, y_{1:t}, \theta)$, and posterior samples of $x_t$ are drawn from the proposed samples or particles using importance weights $w_t$:

```{=tex}
\begin{equation}\label{importanceWeights1}
w_t^{(i)} \propto \frac{p(x_t^{(i)}|x_{t-1}^{(i)}, y_{1:t},\theta)}{\pi(x_t^{(i)}|x_{t-1}^{(i)}, y_{1:t},\theta)}
\end{equation}
```
and iteratively as:

```{=tex}
\begin{equation}\label{importanceWeights2}
w_t^{(i)} \propto w_{t-1}^{(i)} \frac{p(x_t^{(i)}|x_{t-1}^{(i)}\theta) p(y_{1:t}|x_t^{(i)})}{\pi(x_t^{(i)}|x_{t-1}^{(i)}, y_{1:t},\theta)}
\end{equation}
```
for $i = 1, 2, \ldots, M$ particles.

The importance function chosen for importance sampling is critical to the performance of the SMC method [@arulampalam2002tutorial; @doucet2001introduction; @michaud2021sequential]. Practically, the prior distribution of the latent states are chosen as the importance function. In this case, the importance weights in equation \eqref{importanceWeights2} simplifies to:

```{=tex}
\begin{equation}\label{importanceWeights3}
w_t^{(i)} \propto w_{t-1}^{(i)} p(y_t|x_{t}^{(i)}, \theta);
\end{equation}
```
for $i = 1, 2, \ldots, M$ particles [@doucet2001introduction].

The various SMC methods explored in literature include bootstrap filters [@gordon1993novel], auxiliary particle filters [@pitt1999filtering], ensemble Kalman filter [@evensen2003ensemble], particle learning [@carvalho2010particle] etc. Paper three uses the bootstrap and auxiliary particle filters to present a modelling approach to handles data assimilation problems in ecology.

### Particle Markov Chain Monte Carlo (pMCMC) methods

The model parameters $\theta$ described in the state-space model fitted with the SMC methods described above are assumed to be constant. In most ecological applications, $\theta$ is a random variable. Using the Bayesian framework, the joint likelihood of the latent state $\textbf{x}$ and parameter $\theta$ is $\pi(\theta, x_{1:t}| y_{1:t}) = \pi_{\theta}(x_{1:t}|y_{1:t}) \times \pi(\theta);$ where $\pi(\theta)$ is the prior distribution for the parameter $\theta$.

To sample from the joint posterior distribution $\pi(\theta, x_{1:t}| y_{1:t})$, samples of $\theta$ are proposed from MCMC using the Metropolis-Hastings algorithm (described in section \ref{mcmc}) and samples of the latent state $\textbf{x}$ are obtained from SMC methods [@andrieu2010particle]. The acceptance probability of the MCMC Metropolis Hastings algorithm takes into account the likelihood estimated from the SMC method: \begin{equation}\label{MHAR}
\begin{split}
\alpha & = \frac{\pi_{\theta}(y_{1:t}) \pi(\theta^{\star})\pi(\theta|\theta^{\star})}{p_{\theta^{\star}}(y_{1:t}) \pi(\theta)\pi(\theta^{\star}|\theta)};\\
 \text{with} \quad \pi_{\theta}(y_{1:t}) & = \pi_{\theta}(y_{1})\prod_{t=2}^{T}\pi_{\theta}(y_{n}| y_{n-1}) \\
  & = \pi_{\theta}(y_{1})\prod_{t=2}^{T}\sum_{i = 1}^{M} w_{t|\theta}^{i}\\
\end{split}
\end{equation} where $\pi_{\theta}(y_{1:t})$ is the marginal distribution of the observed data given the parameter $\theta$, $w_{t|\theta}^{i}$ is the $i^{th}$ importance weight at time $t$ given the value of $\theta$, $\pi(\theta^{\star})$ and $\pi(\theta)$ is the prior distribution of $\theta^{\star}$ and $\theta$ respectively and $\pi(.|.)$ is the proposal distribution for the parameters $\theta$.

Paper three further uses pMCMC to sample parameters $\theta$ and latent states $\textbf{x}$ as a modelling approach for data assimilation problems in ecology. They are used to update model parameters and latent state posterior distribution from an existing fitted state-space model. The proposed method was implemented by making changes to the random-walk block samplers and particle filters in the R-package \textbf{nimbleSMC} [@michaud2021sequential]. This method is available as an R-package \textbf{nimMCMCSMCupdates} which can be installed from the GitHub repository (\url{https://github.com/Peprah94/nimMCMCSMCupdates}).

### Integrated Nested Lapplace Approximation (INLA)

INLA is used for hierarchical models that can be expressed as linear Gaussian models [@rue2019inla]. INLA approximates the posterior marginal distribution of $\theta$ and latent states $\textbf{x}$ by providing a deterministic algorithm for the Bayesian inference [@blangiardo2015spatial].

To obtain the marginal posterior distributions, INLA aims to provide estimates to: \begin{equation}
\begin{split}
\pi(x_i| \textbf{y}) &= \int \pi(x_i| \theta, \textbf{y}) \pi(\theta| \textbf{y})d\theta ,\\
\pi(\theta_j|\textbf{y}) &= \int \pi(\theta| \textbf{y})d\theta_{-j},
\end{split}
\end{equation} by relying on the Laplace approximation of $\pi(\textbf{x}| \theta, \textbf{y})$. That is, the posterior marginal distribution are approximated as: \begin{equation}
\begin{split}
\pi(\theta|\textbf{y}) &\propto \frac{\pi(\textbf{y}| \textbf{x}, \theta) \pi(\textbf{x}| \theta) \pi(\theta)}{\pi(\textbf{x}| \theta, \textbf{y})} \approx \frac{\pi(\textbf{y}| \textbf{x}, \theta) \pi(\textbf{x}| \theta) \pi(\theta)}{\hat \pi(\textbf{x}| \theta, \textbf{y})} \mid_{\textbf{x} = \textbf{x}^{\star}(\theta)}, \\
\pi(x_i|\theta, \textbf{x}) &\propto  \frac{\pi(\textbf{x}, \theta| \textbf{y})}{\pi(\textbf{x}_{-i}| x_i, \theta, \textbf{y})} \approx \frac{\pi(\textbf{x}, \theta| \textbf{y})}{\hat\pi(\textbf{x}_{-i}| x_i, \theta, \textbf{y})} \mid_{\textbf{x}_{-i} = \textbf{x}_{-i}^{\star}(x-, \theta)}, 
\end{split}
\end{equation} where $\textbf{x}^{\star}(\theta)$ is the mode of $\pi(\textbf{x}| \theta, \textbf{y})$ for a given $\theta$, $\hat\pi(\textbf{x}_{-i}| x_i, \theta, \textbf{y})$ is the Laplace approximation to $\pi(\textbf{x}_{-i}| x_i, \theta, \textbf{y})$ and $\textbf{x}_{-i}^{\star}(x-, \theta)$ is its given mode.

Papers four and seven uses the INLA framework implemented in the R-package \textbf{R-INLA} [@rue2019inla] and another R-package \textbf{inlabru} [@inlabru] which is a wrapper around the \textbf{R-INLA} package.

### MCMC with INLA

INLA is limited in the class of models it can be used to fit. @gomez2018markov proposed the INLA-MCMC methodology to extend the class of models that can be fitted with \textbf{R-INLA}. This method splits the parameter $\theta$ and latent states $\textbf{x}$ into two sets: $\textbf{z}_c$ and $\textbf{z}_{-c}$. The set $\textbf{z}_c$ is assumed to be fixed, and a conditional latent Gaussian model is defined to be fitted with \textbf{R-INLA} to obtain the posterior distribution of $\textbf{z}_{-c}$. Then, the values of $\textbf{z}_c$ are drawn from their posterior distribution using MCMC methods.

Paper four provides an implementation of the INLA-MCMC methodology in NIMBLE, and is available in the R-package \textbf{inlamcmcnimble}. The R-package can be installed from the GitHub repository (\url{https://github.com/Peprah94/myphdthesis}). The implemented INLA-MCMC methodology was used to estimate the classification probabilities in paper seven.

We present a summary of the hierarchical models fitted and the computational methods used in Table \ref{tbl-summary}.

```{=tex}
\begin{table}
\centering
\begin{tabular}{ccc}
\toprule
Paper & Hierarchical models & Computational method \\
\midrule
1 & - & - \\
2 & Point process models & INLA \\
\addlinespace
3 & state-space models & pMCMC, MCMC \\
4 & N-Mixture model, spatial occupancy model & INLA-MCMC, INLA, MCMC \\
\addlinespace
5& Relative abundance model & MCMC\\
6 & Occupancy model & MCMC \\
7 & Occupancy model, Point process model & MCMC, INLA and INLA-MCMC \\
\bottomrule
\end{tabular}
\caption{\label{tbl-summary} Hierarchical models fitted with various computational methods in the various papers included in this thesis.}
\end{table}
```

## Future work

This thesis has enormously contributed to developing statistical methods to model state variables whilst accounting for various sources of biases. However, the thesis opens up for future work to be done. We list three projects that can be explored in the future.

### Model checking

After models have been fitted to observed data, we want to investigate whether the realisations from our model resembles the observed data. Hence, model checks or assessments, usually referred to as goodness-of-fit tests are necessary for Bayesian inference.

Goodness-of-fit tests using posterior predictive checks are performed by simulating data under the model in question using the posterior distribution of the model parameters. The simulated data is compared to the observed data to ascertain if the simulated realisations are consistent with the observed data [@kery2015applied; @chambert2014use]. The consistency between the two datasets are checked with a test statistic. This choice of test statistics needs to be model and problem specific [@kery2015applied]. However, coming up with meaningful statistics to assess hierarchical model fits can be very challenging.

In paper six, we use the Bayesian p-values estimated from the average occupied sites, average abundance and model deviance as test statistics to check various aspects of our model fit. As Figure \ref{fig-posteriorPredCheck} shows, the Bayesian p-values show lack of fit for some of the species. We do acknowledge that goodness-of-fit tests for hierarchical models are still a developing field [@kery2015applied]. We stress with this illustration that the development of good test statistics for data integration problems (especially for multi-species problems) would be a great addition in the future.

```{r, echo=FALSE, fig.align='center'}
#| fig-cap: Bayesian p-values for the pantrap occupancy data estimated from the two integrated models and species occupancy model for three insect groups; A) bumblebees, B) hoverflies and C) solitary bees. Details of the model fitted are presented in Paper six.
#| label: fig-posteriorPredCheck
#| fig-height: 10
#| fig-width: 14
knitr::include_graphics("posteriorPredCheck.png")
```

### Integrated platform for all computational methods

This thesis used various computational methods to obtain the posterior distribution of the model parameters. All of these models are implemented in different platforms and/or R-packages. Future work can be done to integrate all the computational methods in one platform and possibly as a single R-package.

```{r, echo=FALSE, fig.align='center'}
#| fig-cap: Relationships between the computational methods used in this thesis and the future integrated platform perceived. The computational methods used in this thesis are INLA, SMC, MCMC, INLA-MCMC and pMCMC. The importance sampling with MCMC (IS-MCMC) method was not used here, but is described in @berild2022importance.
#| label: fig-futureWork
#| fig-height: 10
#| fig-width: 18
knitr::include_graphics("futureWork.png")
```

Figure \ref{fig-futureWork} presents a flowchart of how the integrated platform can be used to link all the various methods. As discussed in section \ref{computationalMethods}, the INLA-MCMC method is a combination of MCMC and INLA methods, and the pMCMC is a combination of MCMC and SMC methods. Another study by @berild2022importance combined SMC and MCMC to define an importance sampling with INLA (IS-INLA) methodology. In the future, all these methods can be integrated into one platform, where users have a range of modelling techniques available at their disposal. We suggest that NIMBLE can be the platform for this integrated computational methods.

### Application of Bayesian framework to inform hotspots for data collection using Value of information

As we have noted, collecting data with structured surveys can be very expensive. It is therefore important to plan these surveys and collect data that can better complement data generated from opportunistic surveys. A question naturally arises: "Which location(s) should be sampled to obtain much information to complement the opportunistic surveys?".

```{r, echo=FALSE, fig.align='center'}
#| fig-cap: Map showing the distribution of Gulls in Norway. Two square regions have been selected to indicate the locations future data would be collected.
#| label: fig-voi
#| fig-height: 10
#| fig-width: 14
knitr::include_graphics("gbifGullsNorway.jpeg")
```

Value of information is the decision analysis tool that provides decision-makers with the vital information to decide which locations are best to sample. The decision is made based on the expected increase or decrease in the value of obtaining more information [@dakins1999; @eidsvik2015value]. For example, Figure \ref{fig-voi} shows the distribution of Gulls in Norway and two regions we want to collect data from. It is possible to judge from the map that it makes sense to collect data from region $B$ since more opportunistic data are collected around region $A$. However, this may not be the right call to make if the data collected around region $A$ have poor quality. In such a case, it would be better to collect more structured data to correct the biases in the opportunistic data. Ascertaining whether to sample location $A$ or $B$ would require fitting species distribution models - with the sources of biases accounted for using our proposed Bayesian framework - and the value of collecting additional data can then be properly ascertained using the appropriate metric of value (such as cost or model parameter precision). This is left for future work.

\newpage

### References {.unnumbered}

::: {#refs}
:::

\newpage

<!-- \section*{\Large Contents} -->

```{=tex}
\chapter{Conceptual framework for modelling observation errors}
\pagecolor{mybgcolor}
\afterpage{\nopagecolor}
\pagestyle{fancy}
\fancyhead[LO,LE]{}
\fancyhead[RE,RO]{\thepage}
\fancyfoot[CO,CE]{}
```
\newpage

```{=tex}
\pagecolor{mybgcolor1}
\afterpage{\nopagecolor}
```
## A structural model for the process of collecting biodiversity data

\newpage

\includepdf[pages=-]{structural/A_structural_model_for_the_process_of_collecting_biodiversity_data.pdf}

\newpage

<!-- \addcontentsline{toc}{section}{1.2 Model-based ordination with constrained latent variables} -->

## The Point Process Framework for Integrated Modelling of Biodiversity Data

```{=tex}
\pagecolor{mybgcolor1}
\afterpage{\nopagecolor}
```
\newpage

\includepdf[pages=-]{pointProcess/article.pdf}
\includepdf[pages=-]{pointProcess/supplementaryInformation.pdf}

\newpage

```{=tex}
\chapter{Computational advancements}
\pagecolor{mybgcolor}
\afterpage{\nopagecolor}
```
\newpage

## Sequential Monte Carlo methods for data assimilation problems in ecology

```{=tex}
\pagecolor{mybgcolor1}
\afterpage{\nopagecolor}
```
\newpage

```{=tex}
\includepdf[pages=-]{smc/SMC_for_data_assimilation_problems.pdf}
\includepdf[pages=-]{smc/supplementaryOne.pdf}
\includepdf[pages=-]{smc/supplementaryTwo.pdf}
\includepdf[pages=-]{smc/supplementaryThree.pdf}
\includepdf[pages=-]{smc/supplementary4.pdf}
```
\newpage

## Using NIMBLE to implement Markov Chain Monte Carlo with Integrated Nested Laplace approximation

```{=tex}
\pagecolor{mybgcolor1}
\afterpage{\nopagecolor}
```
\newpage

\includepdf[pages=-]{inlaNimble/nimbleWithINLA.pdf}

\newpage

```{=tex}
\chapter{Statistical modelling of observation errors}
\pagecolor{mybgcolor}
\afterpage{\nopagecolor}
```
\newpage

## Modelling heterogeneity in the classification process in multi-species disribution models can improve predictive performance

```{=tex}
\pagecolor{mybgcolor1}
\afterpage{\nopagecolor}
```
\newpage

```{=tex}
\includepdf[pages=-]{accounting/Accounting_for_misclassification_in_multispecies_distribution_models.pdf}
\includepdf[pages=-]{accounting/Supplementary_Information_1.pdf}
\includepdf[pages=-]{accounting/SupplementaryInformation2.pdf}
```
\newpage

## Integrating data from different taxonomic resolutions to better estimate community alpha diversity

```{=tex}
\pagecolor{mybgcolor1}
\afterpage{\nopagecolor}
```
\newpage

```{=tex}
\includepdf[pages=-]{idm/IDM_for_data_from_different_taxonomic_levels.pdf}
\includepdf[pages=-]{idm/SupplementaryInformationOne.pdf}
\includepdf[pages=-]{idm/SupplementaryInfo2.pdf}
```
\newpage

## Modelling species distribution using data from different sources and quality while accounting for uneven sampling effort, imperfect detection and misclassification.

```{=tex}
\pagecolor{mybgcolor1}
\afterpage{\nopagecolor}
```
\newpage

```{=tex}
\includepdf[pages=-]{threeBiases/article.pdf}
\includepdf[pages=-]{threeBiases/supplementaryInformationOne.pdf}
\includepdf[pages=-]{threeBiases/SupplementaryInformationTwo.pdf}
```
